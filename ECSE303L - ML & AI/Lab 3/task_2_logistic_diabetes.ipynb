{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHdMfFcnf_Ki"
   },
   "source": [
    "## Logistic Regression Modeling for Early Stage Diabetes Risk Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1: Getting familiar with linear algebraic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "- Create matrix of size 10*10 with random integer numbers\n",
    "- Compute the following linear algebric operations on the matrix using built in functions supported in Numpy, Scipy etc.\n",
    "  - Find inverse of the matrix and print it\n",
    "  - Calculate dot product of the matrix with same matrix in transpose A.AT\n",
    "  - Decompose the original matrix using eigen decomposition print the eigen values and eigen vectors\n",
    "  - Calculate jacobian matrix \n",
    "  - Calculate hessian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npa\n",
    "import numdifftools as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.random.rand(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80772092,  0.30260031,  0.39155471, -1.78538872, -1.10370659,\n",
       "         0.59872608, -0.38170656,  0.23072012,  1.37402952,  0.17644944],\n",
       "       [ 0.67742376, -0.51788048, -0.95096551,  1.31567213, -0.18551959,\n",
       "        -0.25707236, -0.47887062, -1.05806079,  1.31247957,  0.76803523],\n",
       "       [ 0.86423699, -0.64272325, -0.39575715,  1.26623465,  0.24494028,\n",
       "        -0.63271606,  0.59347883, -0.96193673,  0.93449075, -0.24461815],\n",
       "       [-1.14957835,  0.07206969,  1.41089826, -1.00993666,  1.13918711,\n",
       "        -1.03760676, -0.80431227,  3.43108504, -3.28485073,  0.29811406],\n",
       "       [-2.7386576 ,  0.14321873,  1.70737487, -3.45650899, -0.70833339,\n",
       "         2.40955302,  1.14238617,  3.05604817, -2.78991546, -0.25351041],\n",
       "       [ 2.02045309,  0.26163395, -0.55930917,  3.17332227,  0.00485749,\n",
       "        -0.21320802,  0.23994083, -3.47063222,  1.32473137, -0.12390651],\n",
       "       [ 1.56676686, -0.22715426, -0.72857439,  0.35212509,  0.12296447,\n",
       "         0.38143279,  0.23626817, -2.44744578,  2.02581799, -0.45431414],\n",
       "       [-2.70057907,  0.80083855,  1.10432839, -2.24957483,  0.34787338,\n",
       "         0.99373846, -0.08909621,  2.94403784, -2.22088807,  0.03070689],\n",
       "       [ 1.60448345,  0.3179807 , -0.80509787,  1.72958845,  0.75731206,\n",
       "        -1.31351397,  0.0450077 , -2.00641575,  0.79989743,  0.64448135],\n",
       "       [ 1.63501379, -0.26446184, -1.38910168,  1.87863564, -0.53884806,\n",
       "        -0.96579188, -0.32342322, -0.36996541,  1.2731882 , -0.88872447]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_inv = npa.inv(m)\n",
    "m_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.15667616, 2.94585992, 2.7862475 , 1.61391818, 2.26104627,\n",
       "        3.91355549, 1.98659682, 5.24494633, 3.51118382, 3.3133095 ],\n",
       "       [2.94585992, 2.78946485, 1.634641  , 1.19648629, 1.51014549,\n",
       "        2.25692603, 1.68596389, 3.48490359, 2.50722112, 2.02449552],\n",
       "       [2.7862475 , 1.634641  , 3.08911423, 1.57137393, 1.67911363,\n",
       "        2.35207665, 1.32424329, 3.47581768, 2.9587759 , 1.8134395 ],\n",
       "       [1.61391818, 1.19648629, 1.57137393, 1.26356742, 1.26260084,\n",
       "        1.79693094, 0.92532622, 2.44001542, 1.96729782, 1.26150998],\n",
       "       [2.26104627, 1.51014549, 1.67911363, 1.26260084, 2.42408912,\n",
       "        2.54053972, 1.08804187, 3.14443254, 2.62862841, 1.48587814],\n",
       "       [3.91355549, 2.25692603, 2.35207665, 1.79693094, 2.54053972,\n",
       "        3.93169996, 1.29460055, 4.54872393, 3.26764711, 2.62284206],\n",
       "       [1.98659682, 1.68596389, 1.32424329, 0.92532622, 1.08804187,\n",
       "        1.29460055, 2.05490138, 2.68637461, 2.04657219, 1.70279783],\n",
       "       [5.24494633, 3.48490359, 3.47581768, 2.44001542, 3.14443254,\n",
       "        4.54872393, 2.68637461, 6.46138994, 4.80408012, 3.70457235],\n",
       "       [3.51118382, 2.50722112, 2.9587759 , 1.96729782, 2.62862841,\n",
       "        3.26764711, 2.04657219, 4.80408012, 3.9537954 , 2.53360424],\n",
       "       [3.3133095 , 2.02449552, 1.8134395 , 1.26150998, 1.48587814,\n",
       "        2.62284206, 1.70279783, 3.70457235, 2.53360424, 2.84272271]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(m, m.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.98338811+0.j        ,  0.38973775+0.26045805j,\n",
       "         0.38973775-0.26045805j,  0.10108665+0.62177519j,\n",
       "         0.10108665-0.62177519j, -0.07193551+0.37964314j,\n",
       "        -0.07193551-0.37964314j, -0.51057664+0.32377085j,\n",
       "        -0.51057664-0.32377085j, -0.94204415+0.j        ]),\n",
       " array([[-0.36968667+0.j        , -0.28116214+0.10631745j,\n",
       "         -0.28116214-0.10631745j,  0.06881063-0.39858691j,\n",
       "          0.06881063+0.39858691j,  0.43007413+0.14445737j,\n",
       "          0.43007413-0.14445737j, -0.27490474-0.08512556j,\n",
       "         -0.27490474+0.08512556j,  0.01493106+0.j        ],\n",
       "        [-0.30563113+0.j        ,  0.06712817+0.29239713j,\n",
       "          0.06712817-0.29239713j, -0.17044362-0.18162464j,\n",
       "         -0.17044362+0.18162464j,  0.11558963-0.2325493j ,\n",
       "          0.11558963+0.2325493j , -0.14998371+0.25956991j,\n",
       "         -0.14998371-0.25956991j,  0.52245275+0.j        ],\n",
       "        [-0.26175657+0.j        ,  0.01655073-0.20276268j,\n",
       "          0.01655073+0.20276268j, -0.22850178+0.26669055j,\n",
       "         -0.22850178-0.26669055j, -0.14923749-0.18469678j,\n",
       "         -0.14923749+0.18469678j,  0.15829443+0.170513j  ,\n",
       "          0.15829443-0.170513j  ,  0.09060887+0.j        ],\n",
       "        [-0.19699861+0.j        ,  0.52745592+0.j        ,\n",
       "          0.52745592-0.j        , -0.2095983 +0.33785669j,\n",
       "         -0.2095983 -0.33785669j, -0.46586297+0.j        ,\n",
       "         -0.46586297-0.j        ,  0.08468199-0.12224665j,\n",
       "          0.08468199+0.12224665j,  0.01778457+0.j        ],\n",
       "        [-0.23928782+0.j        , -0.14147685-0.30405475j,\n",
       "         -0.14147685+0.30405475j,  0.42999402+0.j        ,\n",
       "          0.42999402-0.j        ,  0.13754753+0.44133832j,\n",
       "          0.13754753-0.44133832j, -0.31359086+0.1270621j ,\n",
       "         -0.31359086-0.1270621j , -0.53381497+0.j        ],\n",
       "        [-0.33799913+0.j        ,  0.01455571+0.14341289j,\n",
       "          0.01455571-0.14341289j, -0.17759718-0.31908993j,\n",
       "         -0.17759718+0.31908993j,  0.16626645-0.26393432j,\n",
       "          0.16626645+0.26393432j, -0.04741115+0.01981727j,\n",
       "         -0.04741115-0.01981727j, -0.35798408+0.j        ],\n",
       "        [-0.20828371+0.j        , -0.4429799 -0.24104085j,\n",
       "         -0.4429799 +0.24104085j,  0.35774849+0.03217427j,\n",
       "          0.35774849-0.03217427j,  0.05165249+0.1679887j ,\n",
       "          0.05165249-0.1679887j ,  0.22625577-0.2098608j ,\n",
       "          0.22625577+0.2098608j ,  0.4827426 +0.j        ],\n",
       "        [-0.48255326+0.j        ,  0.206028  +0.02458711j,\n",
       "          0.206028  -0.02458711j,  0.0531375 +0.04722894j,\n",
       "          0.0531375 -0.04722894j,  0.01379552+0.15879766j,\n",
       "          0.01379552-0.15879766j, -0.17513565-0.1831856j ,\n",
       "         -0.17513565+0.1831856j , -0.10052913+0.j        ],\n",
       "        [-0.37156072+0.j        , -0.061     +0.02771078j,\n",
       "         -0.061     -0.02771078j, -0.04343508+0.15981725j,\n",
       "         -0.04343508-0.15981725j, -0.15208075-0.14844522j,\n",
       "         -0.15208075+0.14844522j, -0.06605311+0.01500987j,\n",
       "         -0.06605311-0.01500987j, -0.2467253 +0.j        ],\n",
       "        [-0.27712313+0.j        ,  0.09905669+0.23476932j,\n",
       "          0.09905669-0.23476932j, -0.1116601 -0.02675941j,\n",
       "         -0.1116601 +0.02675941j, -0.13058226-0.15426918j,\n",
       "         -0.13058226+0.15426918j,  0.68548285+0.j        ,\n",
       "          0.68548285-0.j        ,  0.03410286+0.j        ]]))"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eigen value and vector\n",
    "w, v = npa.eig(m)\n",
    "w, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.24534997e+00, 1.33938821e+00, 1.03967835e-01, 2.72191646e+00,\n",
       "         2.81646402e+00, 5.89997629e-01, 2.76265645e+00, 4.55160763e-02,\n",
       "         2.11866845e+00, 1.72610337e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [1.13745271e+00, 1.12692543e-02, 1.04977855e-02, 2.02262223e-01,\n",
       "         5.37973237e-01, 6.64837433e-01, 2.47788893e-01, 1.74877613e+00,\n",
       "         2.65133662e+00, 1.15620025e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [2.35005659e+00, 1.43727615e-01, 1.97498086e+00, 2.12045863e+00,\n",
       "         3.57127588e-01, 1.78740573e+00, 4.25160030e-01, 9.94504600e-02,\n",
       "         1.77171162e-03, 7.20350060e-03],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [1.66501772e-01, 6.67602586e-01, 7.74368211e-01, 2.47287735e-01,\n",
       "         1.29447985e-01, 8.46464405e-01, 9.63317013e-03, 7.14578688e-01,\n",
       "         1.06177700e-03, 2.33755942e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [1.21648515e-02, 6.19379130e-01, 1.14562199e+00, 6.09950401e-01,\n",
       "         1.61632701e-02, 6.48833179e-02, 2.42547378e+00, 2.18415561e+00,\n",
       "         1.71191176e-01, 2.32838403e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [2.56845082e-01, 2.98847305e+00, 1.39322159e-01, 1.06576249e+00,\n",
       "         1.39897846e+00, 1.02971169e+00, 2.71490111e+00, 1.40480570e+00,\n",
       "         1.28078701e-01, 6.68221435e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [2.59618397e-01, 1.21389109e-02, 2.21704565e+00, 8.82169030e-04,\n",
       "         1.18272806e+00, 7.41056520e-03, 5.09985381e-06, 2.08789654e-01,\n",
       "         2.00902365e+00, 2.67061985e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [1.89879051e+00, 2.58349655e+00, 2.22535233e+00, 2.19999040e+00,\n",
       "         2.12555732e+00, 6.85002195e-01, 1.66256317e+00, 2.00574469e+00,\n",
       "         1.63786274e+00, 2.35980991e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [2.07090637e+00, 1.07705215e+00, 2.92789582e+00, 8.77283274e-01,\n",
       "         3.73736935e-01, 4.70171302e-01, 1.16354458e+00, 1.85837483e+00,\n",
       "         4.76666261e-01, 5.65754666e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [7.86872253e-01, 2.73547701e+00, 2.11750921e-01, 6.31518165e-01,\n",
       "         1.45537244e+00, 1.40551755e-01, 1.37582702e-01, 9.36219676e-02,\n",
       "         2.24137195e+00, 9.40489652e-02]]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Jacobian Matrix\n",
    "func = lambda x : x**3\n",
    "nd.Jacobian(func)(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 453.98849416, -258.61596842,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [-258.61596842,  210.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rosen(x): return (1-x[0])**2 + 105.*(x[1]-x[0]**2)**2\n",
    "nd.Hessian(rosen)(m[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2: Logistic Regression using newton method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LWrifqkf_Kj"
   },
   "source": [
    "### Logistic regression\n",
    "Logistic regression uses an equation as the representation, very much like linear regression.\n",
    "\n",
    "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
    "\n",
    "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at <strong>\"data/diabetes_data.csv\"</strong> in the respective challenge's repo.<br>\n",
    "<strong>Original Source:</strong> http://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv. The dataset just got released in July 2020.<br><br>\n",
    "\n",
    "#### Features (X)\n",
    "\n",
    "1. Age                - Values ranging from 16-90\n",
    "2. Gender             - Binary value (Male/Female)\n",
    "3. Polyuria           - Binary value (Yes/No)\n",
    "4. Polydipsia         - Binary value (Yes/No)\n",
    "5. sudden weight loss - Binary value (Yes/No)\n",
    "6. weakness           - Binary value (Yes/No)\n",
    "7. Polyphagia         - Binary value (Yes/No)\n",
    "8. Genital thrush     - Binary value (Yes/No)\n",
    "9. visual blurring    - Binary value (Yes/No)\n",
    "10. Itching           - Binary value (Yes/No)\n",
    "11. Irritability      - Binary value (Yes/No)\n",
    "12. delayed healing   - Binary value (Yes/No)\n",
    "13. partial paresis   - Binary value (Yes/No)\n",
    "14. muscle stiffness  - Binary value (Yes/No)\n",
    "15. Alopecia          - Binary value (Yes/No)\n",
    "16. Obesity           - Binary value (Yes/No)\n",
    "\n",
    "#### Output/Target target (Y) \n",
    "17. class - Binary class (Positive/Negative)\n",
    "\n",
    "#### Objective\n",
    "To learn logistic regression and practice handling of both numerical and categorical features\n",
    "\n",
    "#### Tasks\n",
    "- Download, load the data and print first 5 and last 5 rows\n",
    "- Transform categorical features into numerical features. Use label encoding or any other suitable preprocessing technique\n",
    "- Since the age feature is in larger range, age column can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (Example - sklearn.preprocessing.MinMaxScaler class)\n",
    "- Define X matrix (independent features) and y vector (target feature)\n",
    "- Split the dataset into 60% for training and rest 40% for testing (sklearn.model_selection.train_test_split function)\n",
    "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
    "- Use the trained model to predict on testing set\n",
    "- Print 'Accuracy' obtained on the testing dataset i.e. (sklearn.metrics.accuracy_score function)\n",
    "\n",
    "#### Further fun (will not be evaluated)\n",
    "- Plot loss curve (Loss vs number of iterations)\n",
    "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
    "- Training model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
    "- Shuffling of training samples with different *random seed values* in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Print other classification metrics such as:\n",
    "    - classification report (sklearn.metrics.classification_report),\n",
    "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
    "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
    "\n",
    "#### Helpful links\n",
    "- Scikit-learn documentation for logistic regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
    "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-i4VgviHf_Kk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooYDzG4SnErt"
   },
   "outputs": [],
   "source": [
    "# Download the dataset from the source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqZrgW_if_Kq"
   },
   "outputs": [],
   "source": [
    "# NOTE: DO NOT CHANGE THE VARIABLE NAME(S) IN THIS CELL\n",
    "# Load the data\n",
    "data = pd.read_csv('data/diabetes_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "0   40   Male       No        Yes                 No      Yes         No   \n",
       "1   58   Male       No         No                 No      Yes         No   \n",
       "2   41   Male      Yes         No                 No      Yes        Yes   \n",
       "3   45   Male       No         No                Yes      Yes        Yes   \n",
       "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
       "\n",
       "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "0             No              No     Yes           No             Yes   \n",
       "1             No             Yes      No           No              No   \n",
       "2             No              No     Yes           No             Yes   \n",
       "3            Yes              No     Yes           No             Yes   \n",
       "4             No             Yes     Yes          Yes             Yes   \n",
       "\n",
       "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "0              No              Yes      Yes     Yes  Positive  \n",
       "1             Yes               No      Yes      No  Positive  \n",
       "2              No              Yes      Yes      No  Positive  \n",
       "3              No               No       No      No  Positive  \n",
       "4             Yes              Yes      Yes     Yes  Positive  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Polyuria', 'Polydipsia', 'sudden weight loss',\n",
       "       'weakness', 'Polyphagia', 'Genital thrush', 'visual blurring',\n",
       "       'Itching', 'Irritability', 'delayed healing', 'partial paresis',\n",
       "       'muscle stiffness', 'Alopecia', 'Obesity', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjCRzhp_f_Kw"
   },
   "outputs": [],
   "source": [
    "# Handle categorical/binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Polyuria  Polydipsia  sudden weight loss  weakness  \\\n",
       "0   40       1         0           1                   0         1   \n",
       "1   58       1         0           0                   0         1   \n",
       "2   41       1         1           0                   0         1   \n",
       "3   45       1         0           0                   1         1   \n",
       "4   60       1         1           1                   1         1   \n",
       "\n",
       "   Polyphagia  Genital thrush  visual blurring  Itching  Irritability  \\\n",
       "0           0               0                0        1             0   \n",
       "1           0               0                1        0             0   \n",
       "2           1               0                0        1             0   \n",
       "3           1               1                0        1             0   \n",
       "4           1               0                1        1             1   \n",
       "\n",
       "   delayed healing  partial paresis  muscle stiffness  Alopecia  Obesity  \\\n",
       "0                1                0                 1         1        1   \n",
       "1                0                1                 0         1        0   \n",
       "2                1                0                 1         1        0   \n",
       "3                1                0                 0         0        0   \n",
       "4                1                1                 1         1        1   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name in data.columns:\n",
    "    if(name != 'Age'):\n",
    "        data[name] = encoder.fit_transform(data[name])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aNK0lA1f_Kz"
   },
   "outputs": [],
   "source": [
    "# Normalize the age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqCVUtIUf_K3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atr0       Age  Gender  Polyuria  Polydipsia  sudden weight loss  weakness  \\\n",
       "0     1  0.324324       1         0           1                   0         1   \n",
       "1     1  0.567568       1         0           0                   0         1   \n",
       "2     1  0.337838       1         1           0                   0         1   \n",
       "3     1  0.391892       1         0           0                   1         1   \n",
       "4     1  0.594595       1         1           1                   1         1   \n",
       "\n",
       "   Polyphagia  Genital thrush  visual blurring  Itching  Irritability  \\\n",
       "0           0               0                0        1             0   \n",
       "1           0               0                1        0             0   \n",
       "2           1               0                0        1             0   \n",
       "3           1               1                0        1             0   \n",
       "4           1               0                1        1             1   \n",
       "\n",
       "   delayed healing  partial paresis  muscle stiffness  Alopecia  Obesity  \\\n",
       "0                1                0                 1         1        1   \n",
       "1                0                1                 0         1        0   \n",
       "2                1                0                 1         1        0   \n",
       "3                1                0                 0         0        0   \n",
       "4                1                1                 1         1        1   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "age_norm = scaler.fit_transform(pd.DataFrame(data.Age))\n",
    "data.Age = age_norm\n",
    "data.insert(0, \"Atr0\", [1]*len(data), allow_duplicates=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Uc-BEzqf_K-"
   },
   "outputs": [],
   "source": [
    "# Define your X and y\n",
    "X = data.loc[:, data.columns != 'class'].values\n",
    "y = np.array(data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIiMrIaajX-Q"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    '''Predict class for X.\n",
    "    For the given dataset, predicted vector has only values 0/1\n",
    "    Args:\n",
    "        X : Numpy array (num_samples, num_features)\n",
    "        weights : Model weights for logistic regression\n",
    "    Returns:\n",
    "        Binary predictions : (num_samples,)\n",
    "    '''\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    z = X@weights\n",
    "    logits = sigmoid(z)\n",
    "    y_pred = logits.round()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "        '''Sigmoid function: f:R->(0,1)\n",
    "        Args:\n",
    "            z : A numpy array (num_samples,)\n",
    "        Returns:\n",
    "            A numpy array where sigmoid function applied to every element\n",
    "        '''\n",
    "        ### START CODE HERE\n",
    "        sig_z = 1/(1 + np.exp(-z))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
    "        return sig_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    '''Calculate cross entropy loss\n",
    "    Note: Cross entropy is defined for multiple classes/labels as well\n",
    "    but for this dataset we only need binary cross entropy loss\n",
    "    Args:\n",
    "        y_true : Numpy array of true values (0/1) of size (num_samples,)\n",
    "        y_pred : Numpy array of predicted values (probabilites) of size (num_samples,)\n",
    "    Returns:\n",
    "        Cross entropy loss: A scalar value\n",
    "    '''\n",
    "    # Fix 0 values in y_pred\n",
    "    y_pred = np.maximum(np.full(y_pred.shape, 1e-7), np.minimum(np.full(y_pred.shape, 1-1e-7), y_pred))\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    ce_loss = np.sum(-y_true*np.log(y_pred) - (1-y_true)*np.log(1-y_pred))\n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_optimization(X, y, max_iterations=25):\n",
    "    '''Implement netwon method for optimizing weights\n",
    "    Args:\n",
    "        X : Numpy array (num_samples, num_features)\n",
    "        max_iterations : Max iterations to update the weights\n",
    "    Returns:\n",
    "        Optimal weights (num_features,)\n",
    "    '''\n",
    "    num_samples = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    # Initialize random weights\n",
    "    weights = np.random.random(num_features,)\n",
    "    # Initialize losses\n",
    "    losses = []\n",
    "    \n",
    "    # Newton Method\n",
    "    for i in range(max_iterations):\n",
    "        # Predict/Calculate probabilties using sigmoid function\n",
    "        y_p = sigmoid(X@weights)\n",
    "        #cost function\n",
    "        #cost = lambda x : (1/num_samples) * np.sum(-y*np.log(y_p) - (1-y)*np.log(1-y_p))\n",
    "        # Define gradient for J (cost function) i.e. cross entropy loss\n",
    "        #gradient = 1/num_samples * np.sum(X.T@(y_p - y)).T\n",
    "        \n",
    "        #gradient = nd.Jacobian(cost)(X)\n",
    "        gradient = 1/num_samples *(X.T @ (y_p - y))\n",
    "        # Define hessian matrix for cross entropy loss\n",
    "        #hessian = 1/num_samples * np.sum((y_p*(1-y_p))*(X.T@X))\n",
    "        hessian= (1/num_samples)*X.T.dot(np.diag(y_p)).dot(np.diag(1-y_p)).dot(X)\n",
    "        # Update the model using hessian matrix and gradient computed\n",
    "        weights = weights - npa.inv(hessian)@gradient\n",
    "        \n",
    "        # Calculate cross entropy loss\n",
    "        loss = cross_entropy_loss(y, y_p)\n",
    "        print('loss:',loss)\n",
    "        # Append it\n",
    "        losses.append(loss)\n",
    "\n",
    "    return weights, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 355.8675950380468\n",
      "loss: 941.6030163166164\n",
      "loss: 2947.4704712426533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-352-f6312c3c8862>:9: RuntimeWarning: overflow encountered in exp\n",
      "  sig_z = 1/(1 + np.exp(-z))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-451-f22200f95d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewton_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-450-7b860ad418aa>\u001b[0m in \u001b[0;36mnewton_optimization\u001b[0;34m(X, y, max_iterations)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mhessian\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Update the model using hessian matrix and gradient computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Calculate cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.4/libexec/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.4/libexec/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# Train weights\n",
    "weights, losses = newton_optimization(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " exp = np.zeros((num_features, num_features))\n",
    "        for i in range(num_samples):\n",
    "            exp += (y_p[i]*(1-y_p[i]))*(X[i,:].T@X[i,:])\n",
    "        hessian = (1/num_samples) * exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i+1 for i in range(len(losses))], losses)\n",
    "plt.title(\"Loss curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Cross entropy curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_test_acuracy = accuracy_score(y_test, predict(X_test, weights))\n",
    "\n",
    "print(f\"\\nAccuracy in testing set by our model: {our_model_test_acuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare with the scikit learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qhvibx3Xf_LB"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = LogisticRegression(solver='newton-cg', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndXHgNLxf_LD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg', verbose=1)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model. Wait! We will complete this step for you ;)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHOeLfjFjeNh"
   },
   "outputs": [],
   "source": [
    "# Predict on testing set X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eE5g0uoYf_LG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy in testing set by sklearn model: 0.9182692307692307\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy on testing set\n",
    "sklearn_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy in testing set by sklearn model: {sklearn_test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task_2_logistic_diabetes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
